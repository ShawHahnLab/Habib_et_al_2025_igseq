# See https://github.com/shawhahnlab/igseqhelper

import csv
from collections import defaultdict
from Bio import SeqIO

# "germline-genbank" to use readymade IgDiscover outputs from GenBank, or
# "germline" to create them from scratch first
GERMLINE="germline"

# The Ramesh germline D sequences that we observed in the macaques that were
# not present in KIMDB.
RAMESH_D = ["IGHD1-1*01", "IGHD1-39*01", "IGHD3-26*02", "IGHD4-27*02"]

wildcard_constraints:
    sample="[-A-Za-z0-9]+",
    specimen="[A-Za-z0-9]+",
    subject="[A-Za-z0-9]+",
    chain="(heavy|light)",
    celltype="igm|igg",
    chain_type="(alpha|delta|gamma|mu|epsilon|kappa|lambda)",
    locus="(IGH|IGK|IGL)",
    segment="(V|D|J)",
    antibody_type="(IgA|IgD|IgG|IgM|IgE)",
    antibody_isolate=r"[-_A-Za-z0-9\.]+",
    antibody_lineage=r"[-_A-Za-z0-9\.]+",
    accession="[^/]+",
    name="[^/]+",

### Setup

def load_metadata():
    metadata = {}
    for path in Path("metadata").glob("*.[tc]sv"):
        key = path.stem
        kwargs = {}
        if path.suffix == ".tsv":
            kwargs["delimiter"] = "\t"
        with open(path) as f_in:
            metadata[key] = list(csv.DictReader(f_in, **kwargs))
    for path in Path("metadata").glob("*.txt"):
        key = path.stem
        with open(path) as f_in:
            metadata[key] = [line.strip() for line in f_in]
    return metadata

METADATA = load_metadata()

# from `sha256sum filenames`
def load_checksums():
    with open("sha256.txt") as f_in:
        pairs = dict(re.fullmatch(r"([^ ]+) +(.*)", x.strip()).groups()[::-1] for x in f_in)
    return pairs

CHECKSUMS = load_checksums()

def make_target_igdiscover():
    attrs = set()
    for row in METADATA["biosamples"]:
        if row["igseq_Specimen_CellType"] == "IgM+":
            ref = "kimdb" if row["igseq_Chain"] == "heavy" else "sonarramesh"
            locus = {"kappa": "IGK", "lambda": "IGL"}.get(row["igseq_Type"], "IGH")
            subject = row["igseq_Specimen_Subject"]
            attrs.add((ref, locus, subject))
    attrs = list(attrs)
    attrs.sort()
    attrs = {key: val for key, val in zip(("ref", "locus", "subject"), zip(*attrs))}
    return expand(
        ["analysis/igdiscover/{ref}/{locus}/{subject}/stats/stats.json",
        "analysis/igdiscover/{ref}/{locus}/{subject}/custom_j_discovery/J.fasta"],
        zip, **attrs)

def make_target_miningd():
    subjects = set()
    for row in METADATA["biosamples"]:
        if row["igseq_Specimen_CellType"] == "IgM+":
            subjects.add(row["igseq_Specimen_Subject"])
    subjects = list(subjects)
    subjects.sort()
    return expand(
        "analysis/mining-d/{subject}.output.{pval}.txt",
        subject=subjects, pval=("default", "sensitive"))

def make_target_germline(pattern="analysis/germline/{subject}.{locus}/{{segment}}.fasta", extra=None):
    attrs = set()
    for row in METADATA["biosamples"]:
        if row["igseq_Specimen_CellType"] == "IgM+":
            locus = {"kappa": "IGK", "lambda": "IGL"}.get(row["igseq_Type"], "IGH")
            attrs.add((locus, row["igseq_Specimen_Subject"]))
    attrs = list(attrs)
    attrs.sort()
    if extra:
        attrs.extend(extra)
    attrs = {key: val for key, val in zip(("locus", "subject"), zip(*attrs))}
    return expand(expand(pattern, zip, **attrs), segment=["V", "D", "J"])

def make_target_sonar(pattern="analysis/sonar/{subject}.{locus}/{specimen}/output/tables/{specimen}_rearrangements.tsv"):
    attrs = set()
    for row in METADATA["biosamples"]:
        if row["igseq_Specimen_CellType"] == "IgG+":
            locus = {"kappa": "IGK", "lambda": "IGL"}.get(row["igseq_Type"], "IGH")
            subject = row["igseq_Specimen_Subject"]
            specimen = row["igseq_Specimen"]
            attrs.add((subject, locus, specimen))
    attrs = list(attrs)
    attrs.sort()
    attrs = {key: val for key, val in zip(("subject", "locus", "specimen"), zip(*attrs))}
    return expand(pattern, zip, **attrs)

def make_target_igblast_isolates():
    attrs = set()
    for row in METADATA["isolates"]:
        attrs.add((row["subject"], "IGH"))
        if row["light_sequence"]:
            attrs.add((row["subject"], row["light_locus"]))
    attrs = list(attrs)
    attrs.sort()
    attrs = {key: val for key, val in zip(("subject", "locus"), zip(*attrs))}
    return expand("analysis/isolates/{subject}.{locus}/igblast.tsv", zip, **attrs)

TARGET_TRIM = expand("analysis/trim/{sample}.fastq.gz", sample=[row["sample_name"] for row in METADATA["biosamples"]])
TARGET_MERGE = expand("analysis/merge/{sample}.fastq.gz", sample=[row["sample_name"] for row in METADATA["biosamples"]])
TARGET_IGDISCOVER = make_target_igdiscover()
TARGET_MININGD = make_target_miningd()
TARGET_GERMLINE = make_target_germline()
TARGET_GERMLINE_GENBANK = make_target_germline(
    "analysis/germline-genbank/{subject}.{locus}/{{segment}}.fasta",
    (("IGH", "5695"), ("IGL", "5695")))
TARGET_SONAR_1 = make_target_sonar()
TARGET_SONAR_2_ID_DIV = make_target_sonar(
    "analysis/sonar/{subject}.{locus}/{specimen}/output/tables/{specimen}_goodVJ_unique_id-div.tab")
TARGET_IGBLAST_ISOLATES = make_target_igblast_isolates()
TARGET_OUTPUT = expand(
    "output/{thing}",
    thing=["fig1b.csv", "fig2a.csv", "tableS2.csv", "tableS3_d_info.csv", "figS3A.fa", "figS3B.fa", "figS3C.fa"])

rule all:
    input: TARGET_GERMLINE + TARGET_GERMLINE_GENBANK + TARGET_SONAR_2_ID_DIV + TARGET_IGBLAST_ISOLATES + TARGET_MININGD + TARGET_OUTPUT

rule all_output:
    input: TARGET_OUTPUT

rule all_igblast_isolates:
    input: TARGET_IGBLAST_ISOLATES

rule all_sonar_1:
    input: TARGET_SONAR_1

rule all_sonar_2_id_div:
    input: TARGET_SONAR_2_ID_DIV

rule all_igdiscover:
    input: TARGET_IGDISCOVER

rule all_miningd:
    input: TARGET_MININGD

rule all_germline:
    input: TARGET_GERMLINE

rule all_germline_genbank:
    input: TARGET_GERMLINE_GENBANK

rule all_trim:
    input: TARGET_TRIM

rule all_merge:
    input: TARGET_MERGE

rule download_genbank:
    output: "analysis/genbank/{accession}.{rettype}"
    shell: "scripts/download_ncbi.py nucleotide {wildcards.accession} {output} {wildcards.rettype}"

rule genbank_igdiscover_5695:
    """The old IgDiscover sequences for 5695 from the RHA1 paper

    We have a newer reference for 5695 now based on KIMDB for heavy chain, but
    here's what was used for the original RHA1 paper.
    """
    output: "analysis/genbank/igdiscover_5695.csv"
    input: expand("analysis/genbank/{accession}.fasta", accession=METADATA["genbank_igdiscover_5695"])
    params:
        pattern=r".*mulatta clone (?P<sequence_id>[^ ]+) immunoglobulin "
            r".*\((?P<locus>IG[HKL])(?P<segment>[VJ])\) mRNA"
    shell: "scripts/tabulate_seqs.py -p '{params.pattern}' -x subject=5695 {input} -o {output}"

rule genbank_igdiscover:
    """The new IgDiscover sequences for all subjects"""
    output: "analysis/genbank/igdiscover.csv"
    input: "genbank-placeholders/igdiscover.txt.gz"
    params:
        pattern=r"Rhesus Macaque (?P<subject>.*) antibody germline sequence for "
            r"locus (?P<locus>IG[HKL]) (?P<segment>[VJ]) segment"
    shell: "scripts/tabulate_seqs.py -p '{params.pattern}' -f gb {input} -o {output}"

rule genbank_isolates_5695:
    """Paired heavy and light chain sequences from 5695 from the RHA1 paper"""
    output: "analysis/genbank/isolates_5695.csv"
    input: expand("analysis/genbank/{accession}.fasta", accession=METADATA["genbank_isolates_5695"])
    # "We used an unbiased FACS strategy to isolate 20,000 individual memory B
    # cells from peripheral blood mononuclear cells (PBMCs) 65 weeks after SHIV
    # infection"
    params:
        pattern=r".*mulatta isolate (?P<antibody_isolate>[^ ]+) .* (?P<chain>[^ ]+) chain"
    shell:
        """
            ./scripts/tabulate_seqs.py -p '{params.pattern}' \
                -x subject=5695 -x antibody_lineage=5695-a -x timepoint=65 \
                {input} -o {output}
        """

rule genbank_isolates:
    """Paired heavy and light chain sequences across lineages"""
    output: "analysis/genbank/isolates.csv"
    input: expand("genbank-placeholders/isolates_{chain}.txt.gz", chain=["heavy", "light"])
    params:
        pattern=r"Rhesus macaque (?P<subject>.*) antibody lineage (?P<antibody_lineage>.*) "
            r"antibody (?P<antibody_isolate>.*) isolated at (?P<timepoint>[0-9]+) weeks "
            r"post-infection, (?P<locus>IG[HKL]) sequence"
    shell: "scripts/tabulate_seqs.py -p '{params.pattern}' -f gb {input} -o {output}"

rule metadata_isolates:
    """Table of paired sequences for all lineages"""
    output: "metadata/isolates.csv"
    input:
        isolates="analysis/genbank/isolates.csv",
        isolates_5695="analysis/genbank/isolates_5695.csv"
    shell: "scripts/convert_gb_isolates.py {input} {output}"

rule metadata_igdiscover:
    """Table of new IgDiscover sequences for all subjects"""
    output: "metadata/igdiscover.csv"
    input: "analysis/genbank/igdiscover.csv"
    run:
        with open(output[0], "w") as f_out:
            writer = csv.DictWriter(
                f_out,
                ["subject", "locus", "segment", "sequence_id", "sequence"],
                lineterminator="\n")
            writer.writeheader()
            with open(input[0]) as f_in:
                for row in csv.DictReader(f_in):
                    row["sequence_id"] = row["sequence_id"].removeprefix(row["subject"] + "_")
                    writer.writerow(row)

include: "reads.smk"
include: "germline.smk"
include: "isolates.smk"
include: "sonar.smk"
include: "structure.smk"
